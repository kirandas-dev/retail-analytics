{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a63dde92-121d-42d1-8978-fd475b67c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('../data/processed/final_merged_events.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab4a2319-4a91-4877-80aa-c6bef4b50089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'date' is in a string format, convert it to datetime\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Now you can use .dt accessor to extract date components\n",
    "data['day_of_week'] = data['date'].dt.dayofweek\n",
    "data['month'] = data['date'].dt.month\n",
    "data['year'] = data['date'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f8688-1b42-411e-ad57-b1a0e81e5613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#combined_data['rolling_7d_mean'] = combined_data.groupby(['item_id', 'store_id'])['units_sold'].rolling(window=7).mean().reset_index(level=0, drop=True)\n",
    "#combined_data['rolling_30d_sum'] = combined_data.groupby(['item_id', 'store_id'])['units_sold'].rolling(window=30).sum().reset_index(level=0, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1397deaa-b8d4-4811-a5d7-a6fbb8f25419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_data['units_sold_lag_7'] = combined_data.groupby(['item_id', 'store_id'])['units_sold'].shift(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40242fda-c73e-4f6d-8645-289f6e54c15f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1 - Validation MAE with Target Encoding: 2.8351104758193864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n"
     ]
    }
   ],
   "source": [
    "import os  # Import the os module\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from category_encoders import TargetEncoder\n",
    "import joblib  # Import joblib\n",
    "\n",
    "# List of store names\n",
    "store_names = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n",
    "\n",
    "# Define the groups based on your criteria\n",
    "group1 = ['CA_1', 'CA_2', 'CA_3', 'CA_4']\n",
    "group2 = ['TX_1', 'TX_2', 'TX_3']\n",
    "group3 = ['WI_1', 'WI_2', 'WI_3']\n",
    "\n",
    "# Initialize a dictionary to store the trained models and encoders for each group\n",
    "models = {}\n",
    "\n",
    "# Iterate over each group and filter the data accordingly\n",
    "for group_idx, group in enumerate([group1, group2, group3]):\n",
    "    # Filter the data for the current group\n",
    "    group_data = data[data['store_id'].isin(group)]\n",
    "    \n",
    "    # Define features and target variable\n",
    "    date_features = ['day_of_week', 'month', 'year']\n",
    "    categorical_features = ['store_id', 'item_id']\n",
    "    target = 'sales'\n",
    "    \n",
    "    # Split the data into training, validation, and test sets\n",
    "    train_data, test_data = train_test_split(group_data, test_size=0.2, random_state=42)\n",
    "    train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Extract features and target variables for training, validation, and test sets\n",
    "    X_train, y_train = train_data[date_features + categorical_features], train_data[target]\n",
    "    X_val, y_val = val_data[date_features + categorical_features], val_data[target]\n",
    "    X_test, y_test = test_data[date_features + categorical_features], test_data[target]\n",
    "\n",
    "    # Initialize target encoders for categorical features\n",
    "    target_encoders = {}\n",
    "    for feature in categorical_features:\n",
    "        target_encoder = TargetEncoder()\n",
    "        X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
    "        X_val[feature] = target_encoder.transform(X_val[feature])\n",
    "        X_test[feature] = target_encoder.transform(X_test[feature])\n",
    "        target_encoders[feature] = target_encoder\n",
    "\n",
    "    # Initialize and train the Random Forest model on the encoded feature set\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    val_predictions = model.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set using Mean Absolute Error (MAE)\n",
    "    val_mae = mean_absolute_error(y_val, val_predictions)\n",
    "    print(f'Group {group_idx + 1} - Validation MAE with Target Encoding: {val_mae}')\n",
    "\n",
    "    # Store the trained model and encoders in the dictionary for this group\n",
    "    model_and_encoders = {\n",
    "        'model': model,\n",
    "        'encoders': target_encoders\n",
    "    }\n",
    "    \n",
    "    # Define the models directory\n",
    "    models_dir = \"../models/Randomforest\"\n",
    "    os.makedirs(models_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "    \n",
    "    # Define the model file path for saving\n",
    "    model_file_path = os.path.join(models_dir, f'model_group_{group_idx + 1}.joblib')\n",
    "    \n",
    "    # Save the model to the specified file path using joblib\n",
    "    joblib.dump(model_and_encoders, model_file_path)\n",
    "\n",
    "# You can access the models and encoders for each group using the 'models' dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6346137b-ec7e-445f-a3a2-60bd5559bd5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 286\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028182, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 3.410668\n",
      "Group 1 - Validation MAE with Target Encoding: 3.5032749864743495\n",
      "Group 1 - Test RMSE with Target Encoding: 7.833307977149108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 285\n",
      "[LightGBM] [Info] Number of data points in the train set: 9021136, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 2.929159\n",
      "Group 2 - Validation MAE with Target Encoding: 3.0295616100803753\n",
      "Group 2 - Test RMSE with Target Encoding: 6.948324371294832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/945935056.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 285\n",
      "[LightGBM] [Info] Number of data points in the train set: 9021136, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 2.629241\n",
      "Group 3 - Validation MAE with Target Encoding: 2.902307323203704\n",
      "Group 3 - Test RMSE with Target Encoding: 6.3804925466177975\n",
      "Average RMSE across groups: 7.054041631687245\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import lightgbm as lgb  # Import LightGBM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from category_encoders import TargetEncoder\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# List of store names\n",
    "store_names = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n",
    "\n",
    "# Define the groups based on your criteria\n",
    "group1 = ['CA_1', 'CA_2', 'CA_3', 'CA_4']\n",
    "group2 = ['TX_1', 'TX_2', 'TX_3']\n",
    "group3 = ['WI_1', 'WI_2', 'WI_3']\n",
    "\n",
    "# Initialize a dictionary to store the trained models and encoders for each group\n",
    "models = {}\n",
    "\n",
    "# Initialize lists to store RMSE for each group\n",
    "rmse_scores = []\n",
    "\n",
    "# Iterate over each group and filter the data accordingly\n",
    "for group_idx, group in enumerate([group1, group2, group3]):\n",
    "    # Filter the data for the current group\n",
    "    group_data = data[data['store_id'].isin(group)]\n",
    "\n",
    "    # Define features and target variable\n",
    "    date_features = ['day_of_week', 'month', 'year']\n",
    "    categorical_features = ['store_id', 'item_id']\n",
    "    target = 'sales'\n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    train_data, test_data = train_test_split(group_data, test_size=0.2, random_state=42)\n",
    "    train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Extract features and target variables for training, validation, and test sets\n",
    "    X_train, y_train = train_data[date_features + categorical_features], train_data[target]\n",
    "    X_val, y_val = val_data[date_features + categorical_features], val_data[target]\n",
    "    X_test, y_test = test_data[date_features + categorical_features], test_data[target]\n",
    "\n",
    "    # Initialize target encoders for categorical features\n",
    "    target_encoders = {}\n",
    "    for feature in categorical_features:\n",
    "        target_encoder = TargetEncoder()\n",
    "        X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
    "        X_val[feature] = target_encoder.transform(X_val[feature])\n",
    "        X_test[feature] = target_encoder.transform(X_test[feature])\n",
    "        target_encoders[feature] = target_encoder\n",
    "\n",
    "    # Initialize and train the LightGBM model on the encoded feature set\n",
    "    model = lgb.LGBMRegressor()  # Use LightGBMRegressor\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    val_predictions = model.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set using Mean Absolute Error (MAE)\n",
    "    val_mae = mean_absolute_error(y_val, val_predictions)\n",
    "    print(f'Group {group_idx + 1} - Validation MAE with Target Encoding: {val_mae}')\n",
    "\n",
    "    # Store the trained model and encoders in the dictionary for this group\n",
    "    model_and_encoders = {\n",
    "        'model': model,\n",
    "        'encoders': target_encoders\n",
    "    }\n",
    "\n",
    "    # Define the models directory\n",
    "    models_dir = \"../models/LightGBM\"  # Update the directory name\n",
    "    os.makedirs(models_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "    # Define the model file path for saving\n",
    "    model_file_path = os.path.join(models_dir, f'model_group_{group_idx + 1}.joblib')\n",
    "\n",
    "    # Save the model to the specified file path using joblib\n",
    "    joblib.dump(model_and_encoders, model_file_path)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    test_predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate RMSE on the test set\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "    print(f'Group {group_idx + 1} - Test RMSE with Target Encoding: {rmse}')\n",
    "\n",
    "    # Append the RMSE score to the list\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "# Calculate the average RMSE across groups\n",
    "average_rmse = np.mean(rmse_scores)\n",
    "print(f'Average RMSE across groups: {average_rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6d3079c-926e-4fb3-864e-95487faf4389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1 - Validation MAE with Target Encoding: 3.4851860637365495\n",
      "Group 1 - Test RMSE with Target Encoding: 7.8817536483258435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 2 - Validation MAE with Target Encoding: 3.0255307006170726\n",
      "Group 2 - Test RMSE with Target Encoding: 7.01639161125772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_2511/2942416930.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 3 - Validation MAE with Target Encoding: 2.878253019521291\n",
      "Group 3 - Test RMSE with Target Encoding: 6.375807490342143\n",
      "Average RMSE across groups: 7.091317583308569\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xgboost as xgb  # Import XGBoost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from category_encoders import TargetEncoder\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# List of store names\n",
    "store_names = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n",
    "\n",
    "# Define the groups based on your criteria\n",
    "group1 = ['CA_1', 'CA_2', 'CA_3', 'CA_4']\n",
    "group2 = ['TX_1', 'TX_2', 'TX_3']\n",
    "group3 = ['WI_1', 'WI_2', 'WI_3']\n",
    "\n",
    "# Initialize a dictionary to store the trained models and encoders for each group\n",
    "models = {}\n",
    "\n",
    "# Initialize lists to store RMSE for each group\n",
    "rmse_scores = []\n",
    "\n",
    "# Iterate over each group and filter the data accordingly\n",
    "for group_idx, group in enumerate([group1, group2, group3]):\n",
    "    # Filter the data for the current group\n",
    "    group_data = data[data['store_id'].isin(group)]\n",
    "\n",
    "    # Define features and target variable\n",
    "    date_features = ['day_of_week', 'month', 'year']\n",
    "    categorical_features = ['store_id', 'item_id']\n",
    "    target = 'sales'\n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    train_data, test_data = train_test_split(group_data, test_size=0.2, random_state=42)\n",
    "    train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Extract features and target variables for training, validation, and test sets\n",
    "    X_train, y_train = train_data[date_features + categorical_features], train_data[target]\n",
    "    X_val, y_val = val_data[date_features + categorical_features], val_data[target]\n",
    "    X_test, y_test = test_data[date_features + categorical_features], test_data[target]\n",
    "\n",
    "    # Initialize target encoders for categorical features\n",
    "    target_encoders = {}\n",
    "    for feature in categorical_features:\n",
    "        target_encoder = TargetEncoder()\n",
    "        X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
    "        X_val[feature] = target_encoder.transform(X_val[feature])\n",
    "        X_test[feature] = target_encoder.transform(X_test[feature])\n",
    "        target_encoders[feature] = target_encoder\n",
    "\n",
    "    # Initialize and train the XGBoost model on the encoded feature set\n",
    "    model = xgb.XGBRegressor()  # Use XGBRegressor\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    val_predictions = model.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set using Mean Absolute Error (MAE)\n",
    "    val_mae = mean_absolute_error(y_val, val_predictions)\n",
    "    print(f'Group {group_idx + 1} - Validation MAE with Target Encoding: {val_mae}')\n",
    "\n",
    "    # Store the trained model and encoders in the dictionary for this group\n",
    "    model_and_encoders = {\n",
    "        'model': model,\n",
    "        'encoders': target_encoders\n",
    "    }\n",
    "\n",
    "    # Define the models directory\n",
    "    models_dir = \"../models/XGBoost\"  # Update the directory name\n",
    "    os.makedirs(models_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "    # Define the model file path for saving\n",
    "    model_file_path = os.path.join(models_dir, f'model_group_{group_idx + 1}.joblib')\n",
    "\n",
    "    # Save the model to the specified file path using joblib\n",
    "    joblib.dump(model_and_encoders, model_file_path)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    test_predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate RMSE on the test set\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "    print(f'Group {group_idx + 1} - Test RMSE with Target Encoding: {rmse}')\n",
    "\n",
    "    # Append the RMSE score to the list\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "# Calculate the average RMSE across groups\n",
    "average_rmse = np.mean(rmse_scores)\n",
    "print(f'Average RMSE across groups: {average_rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0aefcf-092c-4b9d-9747-d5303ef6775e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "test_data = pd.read_csv('../data/processed/test_final_merged.csv', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e2fb15-dbed-4487-a893-8ef9c49f61bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>date</th>\n",
       "      <th>units_sold</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>sales</th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2015-04-19</td>\n",
       "      <td>1</td>\n",
       "      <td>11512</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.24</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2015-04-20</td>\n",
       "      <td>0</td>\n",
       "      <td>11512</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2015-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>11512</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2015-04-22</td>\n",
       "      <td>0</td>\n",
       "      <td>11512</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>1</td>\n",
       "      <td>11512</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.24</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id      item_id  dept_id cat_id store_id state_id   \n",
       "0  FOODS_1_001_CA_1_evaluation  FOODS_1_001  FOODS_1  FOODS     CA_1       CA  \\\n",
       "1  FOODS_1_001_CA_1_evaluation  FOODS_1_001  FOODS_1  FOODS     CA_1       CA   \n",
       "2  FOODS_1_001_CA_1_evaluation  FOODS_1_001  FOODS_1  FOODS     CA_1       CA   \n",
       "3  FOODS_1_001_CA_1_evaluation  FOODS_1_001  FOODS_1  FOODS     CA_1       CA   \n",
       "4  FOODS_1_001_CA_1_evaluation  FOODS_1_001  FOODS_1  FOODS     CA_1       CA   \n",
       "\n",
       "         date  units_sold  wm_yr_wk  sell_price  sales event_name  event_count  \n",
       "0  2015-04-19           1     11512        2.24   2.24    NoEvent          0.0  \n",
       "1  2015-04-20           0     11512        2.24   0.00    NoEvent          0.0  \n",
       "2  2015-04-21           0     11512        2.24   0.00    NoEvent          0.0  \n",
       "3  2015-04-22           0     11512        2.24   0.00    NoEvent          0.0  \n",
       "4  2015-04-23           1     11512        2.24   2.24    NoEvent          0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c633a0b2-cc5b-45d7-845d-a8cda875c3cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'date' is in a string format, convert it to datetime\n",
    "test_data['date'] = pd.to_datetime(test_data['date'])\n",
    "\n",
    "# Now you can use .dt accessor to extract date components\n",
    "test_data['day_of_week'] = test_data['date'].dt.dayofweek\n",
    "test_data['month'] = test_data['date'].dt.month\n",
    "test_data['year'] = test_data['date'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d1340fa-cba6-4330-bad9-7acf51164f70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>date</th>\n",
       "      <th>units_sold</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>sales</th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_count</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2015-04-19</td>\n",
       "      <td>1</td>\n",
       "      <td>11512</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.24</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2015-04-20</td>\n",
       "      <td>0</td>\n",
       "      <td>11512</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2015-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>11512</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2015-04-22</td>\n",
       "      <td>0</td>\n",
       "      <td>11512</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>1</td>\n",
       "      <td>11512</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.24</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id      item_id  dept_id cat_id store_id state_id   \n",
       "0  FOODS_1_001_CA_1_evaluation  FOODS_1_001  FOODS_1  FOODS     CA_1       CA  \\\n",
       "1  FOODS_1_001_CA_1_evaluation  FOODS_1_001  FOODS_1  FOODS     CA_1       CA   \n",
       "2  FOODS_1_001_CA_1_evaluation  FOODS_1_001  FOODS_1  FOODS     CA_1       CA   \n",
       "3  FOODS_1_001_CA_1_evaluation  FOODS_1_001  FOODS_1  FOODS     CA_1       CA   \n",
       "4  FOODS_1_001_CA_1_evaluation  FOODS_1_001  FOODS_1  FOODS     CA_1       CA   \n",
       "\n",
       "        date  units_sold  wm_yr_wk  sell_price  sales event_name  event_count   \n",
       "0 2015-04-19           1     11512        2.24   2.24    NoEvent          0.0  \\\n",
       "1 2015-04-20           0     11512        2.24   0.00    NoEvent          0.0   \n",
       "2 2015-04-21           0     11512        2.24   0.00    NoEvent          0.0   \n",
       "3 2015-04-22           0     11512        2.24   0.00    NoEvent          0.0   \n",
       "4 2015-04-23           1     11512        2.24   2.24    NoEvent          0.0   \n",
       "\n",
       "   day_of_week  month  year  \n",
       "0            6      4  2015  \n",
       "1            0      4  2015  \n",
       "2            1      4  2015  \n",
       "3            2      4  2015  \n",
       "4            3      4  2015  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb71d2c7-0692-4c80-912f-2142ac2055d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM RMSE for 2016-01-11 00:00:00 in WI_3: 0.48677423170428646\n",
      "LightGBM RMSE for 2016-03-24 00:00:00 in TX_1: 3.1138865529354\n",
      "LightGBM RMSE for 2016-05-10 00:00:00 in CA_3: 5.3578788478683395\n",
      "LightGBM RMSE for 2016-04-12 00:00:00 in TX_2: 0.9024457514828662\n",
      "LightGBM RMSE for 2016-04-24 00:00:00 in CA_3: 30.815673334087982\n",
      "LightGBM RMSE for 2016-01-30 00:00:00 in TX_2: 0.7795138958089556\n",
      "LightGBM RMSE for 2016-04-28 00:00:00 in WI_3: 3.5203834390956046\n",
      "LightGBM RMSE for 2016-03-27 00:00:00 in WI_2: 1.694393400391195\n",
      "LightGBM RMSE for 2016-04-04 00:00:00 in CA_3: 5.8353785330305135\n",
      "LightGBM RMSE for 2016-03-04 00:00:00 in WI_1: 2.474678736183305\n",
      "LightGBM RMSE for 2016-01-19 00:00:00 in WI_1: 3.8064670854149467\n",
      "LightGBM RMSE for 2016-04-07 00:00:00 in CA_2: 9.098840376913074\n",
      "LightGBM RMSE for 2016-02-21 00:00:00 in CA_4: 0.9497030738231784\n",
      "LightGBM RMSE for 2016-02-07 00:00:00 in CA_4: 1.9663429598712536\n",
      "LightGBM RMSE for 2016-01-13 00:00:00 in CA_1: 3.620018836961174\n",
      "LightGBM RMSE for 2016-02-12 00:00:00 in WI_3: 3.0438767854041364\n",
      "LightGBM RMSE for 2016-04-01 00:00:00 in WI_3: 8.997814439399042\n",
      "LightGBM RMSE for 2016-05-05 00:00:00 in TX_3: 13.03622139783508\n",
      "LightGBM RMSE for 2016-01-17 00:00:00 in CA_4: 1.8530160264398814\n",
      "LightGBM RMSE for 2016-03-15 00:00:00 in TX_3: 3.9515285355998113\n",
      "LightGBM RMSE for 2016-05-13 00:00:00 in TX_1: 1.6242432185223172\n",
      "LightGBM RMSE for 2016-05-09 00:00:00 in CA_3: 3.799337152718752\n",
      "LightGBM RMSE for 2016-03-09 00:00:00 in TX_2: 2.1852842009766285\n",
      "LightGBM RMSE for 2016-02-26 00:00:00 in CA_2: 0.5001623156218141\n",
      "LightGBM RMSE for 2016-04-11 00:00:00 in CA_2: 16.35772903578877\n",
      "LightGBM RMSE for 2016-04-13 00:00:00 in WI_2: 15.451284404298807\n",
      "LightGBM RMSE for 2016-03-13 00:00:00 in CA_4: 2.191055937486733\n",
      "LightGBM RMSE for 2016-03-08 00:00:00 in CA_4: 2.234638755943903\n",
      "LightGBM RMSE for 2016-02-07 00:00:00 in TX_3: 1.262614995303826\n",
      "LightGBM RMSE for 2016-01-04 00:00:00 in CA_1: 0.6639256138219554\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define the store names and groups\n",
    "store_names = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n",
    "group1 = ['CA_1', 'CA_2', 'CA_3', 'CA_4']\n",
    "group2 = ['TX_1', 'TX_2', 'TX_3']\n",
    "group3 = ['WI_1', 'WI_2', 'WI_3']\n",
    "\n",
    "# Filter the data for the year 2016\n",
    "test_data_2016 = test_data[test_data['year'] == 2016]\n",
    "\n",
    "# Define the number of random days to select\n",
    "num_random_days = 30\n",
    "\n",
    "# Get a random sample of day indices from the 2016 data\n",
    "random_day_indices = random.sample(test_data_2016.index.tolist(), num_random_days)\n",
    "\n",
    "# Iterate through each randomly selected day\n",
    "for index in random_day_indices:\n",
    "    row = test_data_2016.loc[index]\n",
    "    \n",
    "    # Determine the model_group based on the store_id\n",
    "    store_id = row['store_id']\n",
    "    if store_id in group1:\n",
    "        model_group = 1\n",
    "    elif store_id in group2:\n",
    "        model_group = 2\n",
    "    elif store_id in group3:\n",
    "        model_group = 3\n",
    "    else:\n",
    "        # Handle the case when the store_id doesn't match any group\n",
    "        model_group = None\n",
    "\n",
    "    if model_group is not None:\n",
    "        # Load the trained model for the determined model_group\n",
    "        model_file_path = f\"../models/LightGBM/model_group_{model_group}.joblib\"\n",
    "        loaded_model = joblib.load(model_file_path)\n",
    "\n",
    "        # Prepare the input data for batch prediction\n",
    "        input_data = pd.DataFrame({\n",
    "            'day_of_week': [row['day_of_week']],\n",
    "            'month': [row['month']],\n",
    "            'year': [row['year']],\n",
    "            'store_id': [row['store_id']],\n",
    "            'item_id': [row['item_id']]\n",
    "        })\n",
    "\n",
    "        # Perform target encoding on categorical features using the loaded encoders\n",
    "        for feature, encoder in loaded_model['encoders'].items():\n",
    "            input_data[feature] = encoder.transform(input_data[feature])\n",
    "\n",
    "        # Make batch predictions using the loaded model\n",
    "        predicted_sales_batch = loaded_model['model'].predict(input_data)\n",
    "\n",
    "        # Calculate the squared difference for the batch\n",
    "        squared_diff_batch = (row['sales'] - predicted_sales_batch[0]) ** 2\n",
    "\n",
    "        # Calculate the RMSE for the selected random day\n",
    "        rmse_batch = np.sqrt(squared_diff_batch)\n",
    "\n",
    "        # Print the RMSE for the selected random day\n",
    "        print(f\"LightGBM RMSE for {row['date']} in {row['store_id']}: {rmse_batch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc3c9b88-5acd-4859-9e00-100794479b20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE for 2016-03-22 00:00:00 in CA_1: 1.4539107084274292\n",
      "XGBoost RMSE for 2016-03-29 00:00:00 in CA_2: 1.3406847715377808\n",
      "XGBoost RMSE for 2016-04-29 00:00:00 in TX_2: 2.008944511413574\n",
      "XGBoost RMSE for 2016-03-05 00:00:00 in CA_4: 1.8767356872558594\n",
      "XGBoost RMSE for 2016-03-12 00:00:00 in CA_2: 0.7277894616127014\n",
      "XGBoost RMSE for 2016-01-22 00:00:00 in CA_1: 0.807964563369751\n",
      "XGBoost RMSE for 2016-03-24 00:00:00 in WI_3: 0.6300606727600098\n",
      "XGBoost RMSE for 2016-02-09 00:00:00 in TX_2: 0.11622856140136717\n",
      "XGBoost RMSE for 2016-04-23 00:00:00 in CA_3: 10.2645845413208\n",
      "XGBoost RMSE for 2016-02-26 00:00:00 in WI_2: 7.821893692016602\n",
      "XGBoost RMSE for 2016-01-20 00:00:00 in TX_1: 0.36802172660827637\n",
      "XGBoost RMSE for 2016-03-18 00:00:00 in WI_2: 1.4428066635131835\n",
      "XGBoost RMSE for 2016-04-05 00:00:00 in WI_2: 1.9420690536499023\n",
      "XGBoost RMSE for 2016-01-11 00:00:00 in WI_1: 2.38731728553772\n",
      "XGBoost RMSE for 2016-04-10 00:00:00 in TX_3: 1.0643382644653316\n",
      "XGBoost RMSE for 2016-05-22 00:00:00 in WI_1: 2.757664918899536\n",
      "XGBoost RMSE for 2016-05-17 00:00:00 in TX_2: 0.9596651196479797\n",
      "XGBoost RMSE for 2016-04-06 00:00:00 in CA_4: 0.7555911731719971\n",
      "XGBoost RMSE for 2016-04-11 00:00:00 in CA_4: 8.083566546440125\n",
      "XGBoost RMSE for 2016-02-26 00:00:00 in TX_2: 1.131384015083313\n",
      "XGBoost RMSE for 2016-01-22 00:00:00 in CA_1: 0.4515066528320313\n",
      "XGBoost RMSE for 2016-01-23 00:00:00 in TX_2: 0.5524981617927551\n",
      "XGBoost RMSE for 2016-01-07 00:00:00 in CA_4: 1.5074965953826904\n",
      "XGBoost RMSE for 2016-04-06 00:00:00 in WI_3: 3.0821127891540527\n",
      "XGBoost RMSE for 2016-01-04 00:00:00 in CA_3: 2.993501663208008\n",
      "XGBoost RMSE for 2016-02-09 00:00:00 in WI_1: 1.571633358001709\n",
      "XGBoost RMSE for 2016-03-20 00:00:00 in TX_3: 0.4645075225830082\n",
      "XGBoost RMSE for 2016-04-12 00:00:00 in CA_3: 2.5213513374328613\n",
      "XGBoost RMSE for 2016-04-16 00:00:00 in CA_3: 2.7086681175231933\n",
      "XGBoost RMSE for 2016-03-10 00:00:00 in CA_1: 2.804547071456909\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define the store names and groups\n",
    "store_names = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n",
    "group1 = ['CA_1', 'CA_2', 'CA_3', 'CA_4']\n",
    "group2 = ['TX_1', 'TX_2', 'TX_3']\n",
    "group3 = ['WI_1', 'WI_2', 'WI_3']\n",
    "\n",
    "# Filter the data for the year 2016\n",
    "test_data_2016 = test_data[test_data['year'] == 2016]\n",
    "\n",
    "# Define the number of random days to select\n",
    "num_random_days = 30\n",
    "\n",
    "# Get a random sample of day indices from the 2016 data\n",
    "random_day_indices = random.sample(test_data_2016.index.tolist(), num_random_days)\n",
    "\n",
    "# Iterate through each randomly selected day\n",
    "for index in random_day_indices:\n",
    "    row = test_data_2016.loc[index]\n",
    "    \n",
    "    # Determine the model_group based on the store_id\n",
    "    store_id = row['store_id']\n",
    "    if store_id in group1:\n",
    "        model_group = 1\n",
    "    elif store_id in group2:\n",
    "        model_group = 2\n",
    "    elif store_id in group3:\n",
    "        model_group = 3\n",
    "    else:\n",
    "        # Handle the case when the store_id doesn't match any group\n",
    "        model_group = None\n",
    "\n",
    "    if model_group is not None:\n",
    "        # Load the trained model for the determined model_group\n",
    "        model_file_path = f\"../models/XGBoost/model_group_{model_group}.joblib\"\n",
    "        loaded_model = joblib.load(model_file_path)\n",
    "\n",
    "        # Prepare the input data for batch prediction\n",
    "        input_data = pd.DataFrame({\n",
    "            'day_of_week': [row['day_of_week']],\n",
    "            'month': [row['month']],\n",
    "            'year': [row['year']],\n",
    "            'store_id': [row['store_id']],\n",
    "            'item_id': [row['item_id']]\n",
    "        })\n",
    "\n",
    "        # Perform target encoding on categorical features using the loaded encoders\n",
    "        for feature, encoder in loaded_model['encoders'].items():\n",
    "            input_data[feature] = encoder.transform(input_data[feature])\n",
    "\n",
    "        # Make batch predictions using the loaded model\n",
    "        predicted_sales_batch = loaded_model['model'].predict(input_data)\n",
    "\n",
    "        # Calculate the squared difference for the batch\n",
    "        squared_diff_batch = (row['sales'] - predicted_sales_batch[0]) ** 2\n",
    "\n",
    "        # Calculate the RMSE for the selected random day\n",
    "        rmse_batch = np.sqrt(squared_diff_batch)\n",
    "\n",
    "        # Print the RMSE for the selected random day\n",
    "        print(f\"XGBoost RMSE for {row['date']} in {row['store_id']}: {rmse_batch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c3c42-4a57-4b23-ad5b-0babf855c0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
