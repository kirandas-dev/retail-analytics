{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a63dde92-121d-42d1-8978-fd475b67c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('../data/processed/final_merged_events.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e2fb15-dbed-4487-a893-8ef9c49f61bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcombined_data\u001b[49m\u001b[38;5;241m.\u001b[39mcount()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_data' is not defined"
     ]
    }
   ],
   "source": [
    "combined_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a2cf2-a351-4beb-a418-a4ab7a5f9b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "908df58d-a2e1-479a-9e0e-830e52f88b80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>date</th>\n",
       "      <th>units_sold</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>sales</th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>3</td>\n",
       "      <td>11101</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>11101</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>4</td>\n",
       "      <td>11101</td>\n",
       "      <td>2.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>FOODS_1_021_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_021</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2014-05-20</td>\n",
       "      <td>3</td>\n",
       "      <td>11416</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.94</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>FOODS_1_021_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_021</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2014-05-21</td>\n",
       "      <td>5</td>\n",
       "      <td>11416</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4.90</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>FOODS_1_021_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_021</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2014-05-22</td>\n",
       "      <td>3</td>\n",
       "      <td>11416</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.94</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30489</th>\n",
       "      <td>FOODS_1_021_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_021</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2014-05-23</td>\n",
       "      <td>5</td>\n",
       "      <td>11416</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4.90</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30490</th>\n",
       "      <td>FOODS_1_021_CA_1_evaluation</td>\n",
       "      <td>FOODS_1_021</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2014-05-24</td>\n",
       "      <td>9</td>\n",
       "      <td>11417</td>\n",
       "      <td>0.98</td>\n",
       "      <td>8.82</td>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30491 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id      item_id  dept_id cat_id store_id   \n",
       "0      FOODS_1_001_CA_1_evaluation  FOODS_1_001  FOODS_1  FOODS     CA_1  \\\n",
       "1      FOODS_1_001_CA_1_evaluation  FOODS_1_001  FOODS_1  FOODS     CA_1   \n",
       "2      FOODS_1_001_CA_1_evaluation  FOODS_1_001  FOODS_1  FOODS     CA_1   \n",
       "3      FOODS_1_001_CA_1_evaluation  FOODS_1_001  FOODS_1  FOODS     CA_1   \n",
       "4      FOODS_1_001_CA_1_evaluation  FOODS_1_001  FOODS_1  FOODS     CA_1   \n",
       "...                            ...          ...      ...    ...      ...   \n",
       "30486  FOODS_1_021_CA_1_evaluation  FOODS_1_021  FOODS_1  FOODS     CA_1   \n",
       "30487  FOODS_1_021_CA_1_evaluation  FOODS_1_021  FOODS_1  FOODS     CA_1   \n",
       "30488  FOODS_1_021_CA_1_evaluation  FOODS_1_021  FOODS_1  FOODS     CA_1   \n",
       "30489  FOODS_1_021_CA_1_evaluation  FOODS_1_021  FOODS_1  FOODS     CA_1   \n",
       "30490  FOODS_1_021_CA_1_evaluation  FOODS_1_021  FOODS_1  FOODS     CA_1   \n",
       "\n",
       "      state_id        date  units_sold  wm_yr_wk  sell_price  sales   \n",
       "0           CA  2011-01-29           3     11101        2.00   6.00  \\\n",
       "1           CA  2011-01-30           0     11101        2.00   0.00   \n",
       "2           CA  2011-01-31           0     11101        2.00   0.00   \n",
       "3           CA  2011-02-01           1     11101        2.00   2.00   \n",
       "4           CA  2011-02-02           4     11101        2.00   8.00   \n",
       "...        ...         ...         ...       ...         ...    ...   \n",
       "30486       CA  2014-05-20           3     11416        0.98   2.94   \n",
       "30487       CA  2014-05-21           5     11416        0.98   4.90   \n",
       "30488       CA  2014-05-22           3     11416        0.98   2.94   \n",
       "30489       CA  2014-05-23           5     11416        0.98   4.90   \n",
       "30490       CA  2014-05-24           9     11417        0.98   8.82   \n",
       "\n",
       "      event_name  event_count  \n",
       "0        NoEvent          0.0  \n",
       "1        NoEvent          0.0  \n",
       "2        NoEvent          0.0  \n",
       "3        NoEvent          0.0  \n",
       "4        NoEvent          0.0  \n",
       "...          ...          ...  \n",
       "30486    NoEvent          0.0  \n",
       "30487    NoEvent          0.0  \n",
       "30488    NoEvent          0.0  \n",
       "30489    NoEvent          0.0  \n",
       "30490    NoEvent          0.0  \n",
       "\n",
       "[30491 rows x 13 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.head(30491)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a70e6ff-5f11-4317-9db2-765d9e230301",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1541\n"
     ]
    }
   ],
   "source": [
    "count_rows = combined_data[(combined_data['item_id'] == 'FOODS_1_021') & (combined_data['store_id'] == 'CA_1')].shape[0]\n",
    "print(count_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d80c6b0-304e-44e3-b761-bbfb05b821bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique item_ids: 3049\n"
     ]
    }
   ],
   "source": [
    "unique_item_count = len(target_item_ids)\n",
    "print(\"Number of unique item_ids:\", unique_item_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab4a2319-4a91-4877-80aa-c6bef4b50089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'date' is in a string format, convert it to datetime\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Now you can use .dt accessor to extract date components\n",
    "data['day_of_week'] = data['date'].dt.dayofweek\n",
    "data['month'] = data['date'].dt.month\n",
    "data['year'] = data['date'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f8688-1b42-411e-ad57-b1a0e81e5613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#combined_data['rolling_7d_mean'] = combined_data.groupby(['item_id', 'store_id'])['units_sold'].rolling(window=7).mean().reset_index(level=0, drop=True)\n",
    "#combined_data['rolling_30d_sum'] = combined_data.groupby(['item_id', 'store_id'])['units_sold'].rolling(window=30).sum().reset_index(level=0, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1397deaa-b8d4-4811-a5d7-a6fbb8f25419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_data['units_sold_lag_7'] = combined_data.groupby(['item_id', 'store_id'])['units_sold'].shift(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40242fda-c73e-4f6d-8645-289f6e54c15f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[feature] = target_encoder.transform(X_val[feature])\n",
      "/var/folders/dm/ly88h28j28b8nml3dg1my5bc0000gn/T/ipykernel_3643/2399735645.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = target_encoder.transform(X_test[feature])\n"
     ]
    }
   ],
   "source": [
    "import os  # Import the os module\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from category_encoders import TargetEncoder\n",
    "import joblib  # Import joblib\n",
    "\n",
    "# List of store names\n",
    "store_names = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n",
    "\n",
    "# Define the groups based on your criteria\n",
    "group1 = ['CA_1', 'CA_2', 'CA_3', 'CA_4']\n",
    "group2 = ['TX_1', 'TX_2', 'TX_3']\n",
    "group3 = ['WI_1', 'WI_2', 'WI_3']\n",
    "\n",
    "# Initialize a dictionary to store the trained models and encoders for each group\n",
    "models = {}\n",
    "\n",
    "# Iterate over each group and filter the data accordingly\n",
    "for group_idx, group in enumerate([group1, group2, group3]):\n",
    "    # Filter the data for the current group\n",
    "    group_data = data[data['store_id'].isin(group)]\n",
    "    \n",
    "    # Define features and target variable\n",
    "    date_features = ['day_of_week', 'month', 'year']\n",
    "    categorical_features = ['store_id', 'item_id']\n",
    "    target = 'sales'\n",
    "    \n",
    "    # Split the data into training, validation, and test sets\n",
    "    train_data, test_data = train_test_split(group_data, test_size=0.2, random_state=42)\n",
    "    train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Extract features and target variables for training, validation, and test sets\n",
    "    X_train, y_train = train_data[date_features + categorical_features], train_data[target]\n",
    "    X_val, y_val = val_data[date_features + categorical_features], val_data[target]\n",
    "    X_test, y_test = test_data[date_features + categorical_features], test_data[target]\n",
    "\n",
    "    # Initialize target encoders for categorical features\n",
    "    target_encoders = {}\n",
    "    for feature in categorical_features:\n",
    "        target_encoder = TargetEncoder()\n",
    "        X_train[feature] = target_encoder.fit_transform(X_train[feature], y_train)\n",
    "        X_val[feature] = target_encoder.transform(X_val[feature])\n",
    "        X_test[feature] = target_encoder.transform(X_test[feature])\n",
    "        target_encoders[feature] = target_encoder\n",
    "\n",
    "    # Initialize and train the Random Forest model on the encoded feature set\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    val_predictions = model.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set using Mean Absolute Error (MAE)\n",
    "    val_mae = mean_absolute_error(y_val, val_predictions)\n",
    "    print(f'Group {group_idx + 1} - Validation MAE with Target Encoding: {val_mae}')\n",
    "\n",
    "    # Store the trained model and encoders in the dictionary for this group\n",
    "    model_and_encoders = {\n",
    "        'model': model,\n",
    "        'encoders': target_encoders\n",
    "    }\n",
    "    \n",
    "    # Define the models directory\n",
    "    models_dir = \"../models/Randomforest\"\n",
    "    os.makedirs(models_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "    \n",
    "    # Define the model file path for saving\n",
    "    model_file_path = os.path.join(models_dir, f'model_group_{group_idx + 1}.joblib')\n",
    "    \n",
    "    # Save the model to the specified file path using joblib\n",
    "    joblib.dump(model_and_encoders, model_file_path)\n",
    "\n",
    "# You can access the models and encoders for each group using the 'models' dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "952cb493-cdba-4028-a478-1e7379cad861",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m     10\u001b[0m input_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday_of_week\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m],  \u001b[38;5;66;03m# Replace with the day of the week for your date\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m6\u001b[39m],        \u001b[38;5;66;03m# Replace with the month for your date\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mITEM_ID\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Replace with the desired item_id\u001b[39;00m\n\u001b[1;32m     16\u001b[0m })\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Perform target encoding on categorical features using the loaded encoders\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature, encoder \u001b[38;5;129;01min\u001b[39;00m \u001b[43mloaded_model\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencoders\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     20\u001b[0m     input_data[feature] \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mtransform(input_data[feature])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Make predictions using the loaded model\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/My Research Material/UTSSpring23/AdvancedML/AT2/Retail_Analytics/.venv/lib/python3.10/site-packages/sklearn/ensemble/_base.py:219\u001b[0m, in \u001b[0;36mBaseEnsemble.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m    218\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the index'th estimator in the ensemble.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the trained model for the specific group (e.g., Group 1)\n",
    "model_group = 1\n",
    "model_file_path = f\"../models/model_group_{model_group}.joblib\"\n",
    "loaded_model = joblib.load(model_file_path)\n",
    "\n",
    "# Define the input data for prediction\n",
    "input_data = pd.DataFrame({\n",
    "    'day_of_week': [1],  # Replace with the day of the week for your date\n",
    "    'month': [6],        # Replace with the month for your date\n",
    "    'year': [2016],      # Replace with the year for your date\n",
    "    'store_id': ['CA_1'],  # Replace with the desired store_id\n",
    "    'item_id': ['FOODS_1_001']  # Replace with the desired item_id\n",
    "})\n",
    "\n",
    "# Perform target encoding on categorical features using the loaded encoders\n",
    "for feature, encoder in loaded_model['encoders'].items():\n",
    "    input_data[feature] = encoder.transform(input_data[feature])\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "predicted_sales = loaded_model['model'].predict(input_data)\n",
    "\n",
    "# Print the predicted sales\n",
    "print(f\"Predicted Sales: {predicted_sales[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d3079c-926e-4fb3-864e-95487faf4389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
